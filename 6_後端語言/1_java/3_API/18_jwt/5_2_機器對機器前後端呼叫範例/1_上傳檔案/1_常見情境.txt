ref ChatGPT

🎯 案例情境：檔案上傳（Machine-to-Machine）
	上傳方（Client）：可能是 batch job、前置服務、轉檔服務等，透過 OAuth2 client_credentials 模式取得 JWT
	接收方（Resource Server）：驗證 JWT，接收上傳檔案 /api/files/upload
	使用 multipart/form-data 傳送檔案

		情境1: 前端（或 batch job）直接讀檔並透過 WebClient 傳給後端
		情境2: 兩段式：前端落地再上傳到後端

		情境3: 串流轉送（stream proxy）前端stream不落地轉發到後端落地

			| 模式                         | 說明                                                    | 是否落地檔案 | 適合場景                                   |
			| ---------------------------- | ------------------------------------------------------- | ------------ | ------------------------------------------ |
			| **兩段式：落地再上傳**       | 前端先存檔到暫存目錄，再用 WebClient 或其他方式轉上後端 | ✅ 是        | 大檔案、多階段處理、需稽核/掃毒等          |
			| **串流轉送（stream proxy）** | 前端一邊接收使用者檔案、一邊直接轉送後端，不存本機      | ❌ 否        | 小檔案、低延遲、resource server 可立即處理 |


✅ 實務上怎麼選？
	📦 方案一：兩段式（落地 + 再送）
		前端服務先把 MultipartFile.transferTo() 存到暫存目錄，再呼叫後端上傳該檔案。
			優點：
				可重試、重傳
				可做中間處理（壓縮、掃毒、記錄）
				非同步轉送或排程可行

			缺點：
				暫存空間需求
				效能較差（磁碟 I/O）
				多步驟管理成本高

			常見場景：
				金融、法規要求稽核留存
				大檔案、非即時
				需要暫存等待某個任務（如人工審核）再上傳
	🚀 方案二：串流轉送（streaming proxy）
		前端收到使用者 multipart 請求後，不解析也不落地檔案，直接將整個 HTTP body 以 streaming 傳送到 Resource Server。
			優點：
				最低延遲與資源消耗（無磁碟 I/O）
				輕量架構，容易擴充
				較適合 API Gateway、邊界層

			缺點：
				風險集中（若轉送中斷，資料不留痕）
				錯誤處理與回報困難（使用者不易得知錯在哪）
				無法進行中間處理（如掃毒）

			常見場景：
				小檔案、IoT 裝置、即時圖像傳輸
				前端只是 Gateway 或 Proxy
				輕量化雲原生架構

✅ 雙模式並存也是常見策略
	| 分類方式       | 備註                     |
	| -------------- | ------------------------ |
	| < 5MB 小檔案   | 使用 streaming           |
	| > 50MB 大檔案  | 先落地再分段上傳         |
	| 需掃毒         | 先落地，轉給安全掃毒引擎 |
	| 信任來源系統   | 可直接轉送，不存中間檔   |

🧠 總結建議
	| 你系統需求                               | 建議方式                     |
	| ---------------------------------------- | ---------------------------- |
	| 小檔案、低延遲、使用者體驗第一           | ✅ stream 轉送（proxy 模式） |
	| 大檔案、需處理或稽核、金融醫療等高規環境 | ✅ 兩段式（先落地再上傳）    |
	| 需支援離線重傳、非同步轉送               | ✅ 兩段式更彈性              |
